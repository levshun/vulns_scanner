{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import pylcs\n",
    "from typing import Union, List, Optional\n",
    "from pprint import pprint\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
    "                         pipeline, TrainingArguments, Trainer,\n",
    "                         DataCollatorForTokenClassification, EarlyStoppingCallback)\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset, Features, Sequence, Value, ClassLabel, load_dataset, load_from_disk\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import re\n",
    "\n",
    "\n",
    "print(transformers.__version__)\n",
    "\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "# model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"/home/mikhail/Documents/pandan_study/vkr/vulns_scanner/mikhail_code/models/nuner_as_tok_clf_190425/best_model\"\n",
    "final_tokenizer = AutoTokenizer.from_pretrained(path_to_model, use_fast=True, add_prefix_space=True, local_files_only=True)\n",
    "final_model = AutoModelForTokenClassification.from_pretrained(path_to_model, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models/nuner_as_tok_clf_190425/best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: vendor   Word:  Julien   Prob: 0.9925166\n",
      "Entity: product   Word:  WP Matterport Shortcode   Prob: 0.9509382\n",
      "Entity: version   Word:  <= 2.1.4   Prob: 0.99982387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail/.local/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:398: UserWarning: Tokenizer does not support real words, using fallback heuristic\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "s = \"Auth. (contributor+) Stored Cross-Site Scripting (XSS) vulnerability in Julien Berthelot / MPEmbed WP Matterport Shortcode plugin <= 2.1.4 versions.\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=final_model, aggregation_strategy=\"first\", tokenizer=final_tokenizer\n",
    ")\n",
    "res = token_classifier(s)\n",
    "for i, r in enumerate(res):\n",
    "    # print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'])\n",
    "    print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'] + '   Prob: ' + str(r['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_string: str) -> str:\n",
    "    token_classifier = pipeline(\n",
    "        \"token-classification\", model=final_model, aggregation_strategy=\"first\", tokenizer=final_tokenizer\n",
    "    )\n",
    "    res = token_classifier(input_string)\n",
    "    output = ''\n",
    "    for i, r in enumerate(res):\n",
    "        # print('Entity: '+ r['entity_group'] + '   Word: ' + r['word'])\n",
    "        output += str(f'{i+1}. ' + 'Entity: ' + r['entity_group'] + '   Word: ' + r['word'] + '   Prob: ' + str(r['score']) + '\\n')\n",
    "    # print(output)\n",
    "    if output == '':\n",
    "        output = 'No NER found'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The React Developer Tools extension registers a message listener with window.addEventListener('message', <listener>) in a content script that is accessible to any webpage that is active in the browser. Within the listener is code that requests a URL derived from the received message via fetch(). The URL is not validated or sanitised before it is fetched, thus allowing a malicious web page to arbitrarily fetch URLâ€™s via the victim's browser.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. Entity: version   Word:  before it   Prob: 0.784055\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
